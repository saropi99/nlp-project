{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Sentiment Analysis Classifier\n",
    "\n",
    "##### Group 26: Michal Dawid Kowalski (up202401554) | Pedro Maria Passos Ribeiro do Carmo Pereira (up201708807) | Santiago Romero Pineda (up)\n",
    "\n",
    "In this assignment, we will build a sentiment analysis classifier using traditional machine learning techniques. The process includes pre-processing, feature extraction, and exploring both sparse and dense feature representations like word embeddings. We will use \"traditional\" machine learning classifier instead of deep learning models (CNNs, RNNs, Transformers). The focus will be on understanding text classification techniques and evaluating their performance on the given dataset using common classification metrics like accuracy, precision, recall, and F1-score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "from our_eda import *\n",
    "from our_modeling import *\n",
    "# from our_preprocessing import *\n",
    "from our_feature_extraction import *\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from our_feature_selection import *\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. BESSTIE Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Uploading Dataset Files from HuggingFace (https://huggingface.co/mindhunter23)\n",
    "\n",
    "The dataset is hosted on Hugging Face under the username \"mindhunter23.\" It consists of text data collected from Reddit and Google for the countries UK, AU, and IN. All texts are in English and are labeled with sentiment values: 0 for negative sentiment and 1 for positive sentiment. The dataset is already split into training and validation sets, making it ready for sentiment analysis tasks. It offers diverse content from different regions and platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BESSTIE-reddit-sentiment-uk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'reddit-sentiment-uk-train.jsonl', 'validation': 'reddit-sentiment-uk-valid.jsonl'}\n",
    "df_reddit_sentiment_uk = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-reddit-sentiment-uk/\" + splits[\"train\"], lines=True)\n",
    "df_reddit_sentiment_uk_val = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-reddit-sentiment-uk/\" + splits[\"validation\"], lines=True)\n",
    "df_reddit_sentiment_uk.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training CLasses Distribution\\n')\n",
    "print(class_distribution(df_reddit_sentiment_uk))\n",
    "print('Validation CLasses Distribution\\n')\n",
    "print(class_distribution(df_reddit_sentiment_uk_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BESSTIE-reddit-sentiment-au/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'reddit-sentiment-au-train.jsonl', 'validation': 'reddit-sentiment-au-valid.jsonl'}\n",
    "df_reddit_sentiment_au = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-reddit-sentiment-au/\" + splits[\"train\"], lines=True)\n",
    "df_reddit_sentiment_au_val = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-reddit-sentiment-au/\" + splits[\"validation\"], lines=True)\n",
    "df_reddit_sentiment_au.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training CLasses Distribution\\n')\n",
    "print(class_distribution(df_reddit_sentiment_au))\n",
    "print('Validation CLasses Distribution\\n')\n",
    "print(class_distribution(df_reddit_sentiment_au_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BESSTIE-google-sentiment-uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'google-sentiment-uk-train.jsonl', 'validation': 'google-sentiment-uk-valid.jsonl'}\n",
    "df_google_sentiment_uk = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-google-sentiment-uk/\" + splits[\"train\"], lines=True)\n",
    "df_google_sentiment_uk_val = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-google-sentiment-uk/\" + splits[\"validation\"], lines=True)\n",
    "df_google_sentiment_uk.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training CLasses Distribution\\n')\n",
    "print(class_distribution(df_google_sentiment_uk))\n",
    "print('Validation CLasses Distribution\\n')\n",
    "print(class_distribution(df_google_sentiment_uk_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BESSTIE-google-sentiment-au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'data/google-sentiment-au-train.jsonl', 'validation': 'data/google-sentiment-au-valid.jsonl'}\n",
    "df_google_sentiment_au = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-google-sentiment-au/\" + splits[\"train\"], lines=True)\n",
    "df_google_sentiment_au_val = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-google-sentiment-au/\" + splits[\"validation\"], lines=True)\n",
    "df_google_sentiment_au.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training CLasses Distribution\\n')\n",
    "print(class_distribution(df_google_sentiment_au))\n",
    "print('Validation CLasses Distribution\\n')\n",
    "print(class_distribution(df_google_sentiment_au_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BESSTIE-reddit-sentiment-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'reddit-sentiment-in-train.jsonl', 'validation': 'reddit-sentiment-in-valid.jsonl'}\n",
    "df_reddit_sentiment_in = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-reddit-sentiment-in/\" + splits[\"train\"], lines=True)\n",
    "df_reddit_sentiment_in_val = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-reddit-sentiment-in/\" + splits[\"validation\"], lines=True)\n",
    "df_reddit_sentiment_in.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training CLasses Distribution\\n')\n",
    "print(class_distribution(df_reddit_sentiment_in))\n",
    "print('Validation CLasses Distribution\\n')\n",
    "print(class_distribution(df_reddit_sentiment_in_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BESSTIE-google-sentiment-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'google-sentiment-in-train.jsonl', 'validation': 'google-sentiment-in-valid.jsonl'}\n",
    "df_google_sentiment_in = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-google-sentiment-in/\" + splits[\"train\"], lines=True)\n",
    "df_google_sentiment_in_val = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-google-sentiment-in/\" + splits[\"validation\"], lines=True)\n",
    "df_google_sentiment_in.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training CLasses Distribution\\n')\n",
    "print(class_distribution(df_google_sentiment_in))\n",
    "print('Validation CLasses Distribution\\n')\n",
    "print(class_distribution(df_google_sentiment_in_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Initial Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Testing text_preprocess() func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the preprocessing function \n",
    "print('Original:\\n', df_reddit_sentiment_uk.loc[0].text,'\\n')\n",
    "print('Lemmatization:\\n',text_preprocess(df_reddit_sentiment_uk.loc[0].text, remove_digits=True, stemmer=Stemmer.WordNet),'\\n')\n",
    "print('Stemming:\\n',text_preprocess(df_reddit_sentiment_uk.loc[0].text),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Concatening datasets\n",
    "### SENTIMENT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assue all datasets are already loaded as DataFrames\n",
    "combined_sentiment_df = pd.concat(\n",
    "    [\n",
    "        df_reddit_sentiment_uk,\n",
    "        df_reddit_sentiment_au,\n",
    "        df_google_sentiment_uk,\n",
    "        df_google_sentiment_au,\n",
    "        df_reddit_sentiment_in,\n",
    "        df_google_sentiment_in\n",
    "    ],\n",
    "    axis=0,  # Concatenate vertically (row-wise)\n",
    "    ignore_index=True  # Reset the index in the combined DataFrame\n",
    ")\n",
    "\n",
    "# Assue all datasets are already loaded as DataFrames\n",
    "combined_sentiment_df_val = pd.concat(\n",
    "    [\n",
    "        df_reddit_sentiment_uk_val,\n",
    "        df_reddit_sentiment_au_val,\n",
    "        df_google_sentiment_uk_val,\n",
    "        df_google_sentiment_au_val,\n",
    "        df_reddit_sentiment_in_val,\n",
    "        df_google_sentiment_in_val\n",
    "    ],\n",
    "    axis=0,  # Concatenate vertically (row-wise)\n",
    "    ignore_index=True  # Reset the index in the combined DataFrame\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined data\n",
    "combined_sentiment_df.to_csv(\"data_sentiment_preprocessed.csv\", index=False)\n",
    "combined_sentiment_df_val.to_csv(\"data_sentiment_preprocessed_val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional, when already have necessary data files\n",
    "# combined_sentiment_df = pd.read_csv(\"data_sentiment_preprocessed.csv\")\n",
    "# combined_sentiment_df_val = pd.read_csv(\"data_sentiment_preprocessed_val.csv\")\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(f\"Total rows in combined training dataset: {len(combined_sentiment_df)}\\n\")\n",
    "print('\\nClasses Distribution in Training Dataset:\\n')\n",
    "class_distribution(combined_sentiment_df)\n",
    "print('\\n')\n",
    "plt.figure(figsize=(6,4))\n",
    "combined_sentiment_df['sentiment_label'].value_counts().plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution of Sentiment Labels (Training)')\n",
    "plt.xlabel('Sentiment Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "print(\"Training Dataset:\\n\")\n",
    "combined_sentiment_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the combined DataFrame\n",
    "print(f\"Total rows in combined validation dataset: {len(combined_sentiment_df_val)}\\n\")\n",
    "print('\\nClasses Distribution in Validation Dataset:\\n')\n",
    "class_distribution(combined_sentiment_df)\n",
    "print('\\n')\n",
    "plt.figure(figsize=(6,4))\n",
    "combined_sentiment_df_val['sentiment_label'].value_counts().plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution of Sentiment Labels (Validation)')\n",
    "plt.xlabel('Sentiment Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "print(\"Validation Dataset:\\n\")\n",
    "combined_sentiment_df_val.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of characters per review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "combined_sentiment_df['text'].str.len().hist(bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Text Length (Character Count)', fontsize=12)\n",
    "plt.xlabel('Character Count', fontsize=10)\n",
    "plt.ylabel('Sample Count', fontsize=10)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax1.hist(combined_sentiment_df[combined_sentiment_df['sentiment_label'] == 1]['text'].str.len(), bins=50, color='skyblue', edgecolor='black')\n",
    "ax1.set_title('Positive Reviews', fontsize=12)\n",
    "ax1.set_xlabel('Character Count', fontsize=10)\n",
    "ax1.set_ylabel('Sample Count', fontsize=10)\n",
    "ax1.tick_params(axis='both', labelsize=8)\n",
    "ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "ax2.hist(combined_sentiment_df[combined_sentiment_df['sentiment_label'] == 0]['text'].str.len(), bins=50, color='skyblue', edgecolor='black')\n",
    "ax2.set_title('Negative Reviews', fontsize=12)\n",
    "ax2.set_xlabel('Character Count', fontsize=10)\n",
    "ax2.set_ylabel('Sample Count', fontsize=10)\n",
    "ax2.tick_params(axis='both', labelsize=8)\n",
    "ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSITIVE SENTIMENT\n",
    "text = \" \".join(i for i in combined_sentiment_df[combined_sentiment_df['sentiment_label']==1]['text'])\n",
    "wordcloud = WordCloud(background_color=\"white\").generate(text)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Wordcloud for positive reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEGATIVE SENTIMENT\n",
    "text = \" \".join(i for i in combined_sentiment_df[combined_sentiment_df['sentiment_label']==0]['text'])\n",
    "wordcloud = WordCloud( background_color=\"white\").generate(text)\n",
    "\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Wordcloud for negative reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing + Lemmatization \n",
    "combined_sentiment_df['clean_text'] = combined_sentiment_df['text'].apply(lambda x: text_preprocess(x, remove_digits=True, stemmer=Stemmer.WordNet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "combined_sentiment_df['tokenized_text'] = combined_sentiment_df['clean_text'].apply(lambda x: word_tokenize(x))\n",
    "combined_sentiment_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed training data\n",
    "combined_sentiment_df.to_csv('data_sentiment_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing + Lemmatization \n",
    "combined_sentiment_df_val['clean_text'] = combined_sentiment_df_val['text'].apply(lambda x: text_preprocess(x, remove_digits=True, stemmer=Stemmer.WordNet))\n",
    "# Tokenization\n",
    "combined_sentiment_df_val['tokenized_text'] = combined_sentiment_df_val['clean_text'].apply(lambda x: word_tokenize(x))\n",
    "combined_sentiment_df_val.head(5)\n",
    "# Save preprocessed validation data\n",
    "combined_sentiment_df_val.to_csv('data_sentiment_preprocessed_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOU CAN START FROM THIS POINT GUYS!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional, when already have necessary data files\n",
    "combined_sentiment_df = pd.read_csv('data_sentiment_preprocessed.csv')\n",
    "combined_sentiment_df_val = pd.read_csv('data_sentiment_preprocessed_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Missing Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_sentiment_df.isnull().value_counts())\n",
    "combined_sentiment_df = combined_sentiment_df.dropna() # Drop rows where preprocessing didnt extract any tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_sentiment_df_val.isnull().value_counts())\n",
    "combined_sentiment_df_val = combined_sentiment_df_val.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization because after reading from the file list with tokens converts into str\n",
    "combined_sentiment_df['tokenized_text'] = combined_sentiment_df['clean_text'].apply(lambda x: word_tokenize(x))\n",
    "combined_sentiment_df_val['tokenized_text'] = combined_sentiment_df_val['clean_text'].apply(lambda x: word_tokenize(x))\n",
    "combined_sentiment_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique words before and after the preprocessing\n",
    "all_words = ' '.join(combined_sentiment_df['text']).split()\n",
    "unique_words = set(all_words)\n",
    "\n",
    "all_words_clean = ' '.join(combined_sentiment_df['clean_text']).split()\n",
    "unique_words_clean = set(all_words_clean)\n",
    "\n",
    "labels = ['Unique Words in Raw Text', 'Unique Words in Cleaned Text']\n",
    "sizes = [len(unique_words), len(unique_words_clean)]\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie(sizes, labels=labels, autopct=lambda p: f'{int(p * sum(sizes) / 100)}', startangle=90, colors = ['#FF6347', 'skyblue'])\n",
    "plt.title('Comparison of Unique Words in Raw vs Cleaned Text')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train = combined_sentiment_df.clean_text\n",
    "y_train = combined_sentiment_df.sentiment_label\n",
    "X_val = combined_sentiment_df_val.clean_text\n",
    "y_val = combined_sentiment_df_val.sentiment_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Basic BoW\n",
    "+ removing words that occurs less than 3 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X_train and X_val into proper type \n",
    "X_train_str = [' '.join(tokens) for tokens in combined_sentiment_df.tokenized_text]\n",
    "X_val_str = [' '.join(tokens) for tokens in combined_sentiment_df_val.tokenized_text]\n",
    "\n",
    "word_counts, vocab, selected_words, vectorizer, X_train_vec, X_val_vec = basic_bag(X_train_str, X_val_str, min_refs=2, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 most common words\n",
    "word_counts = np.asarray(X_train_vec.sum(axis=0)).flatten()\n",
    "vocab = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "top_indices = np.argsort(word_counts)[::-1]\n",
    "top_words = vocab[top_indices[:10]]\n",
    "top_counts = word_counts[top_indices[:10]]\n",
    "\n",
    "print('Top 10 most common words:\\n')\n",
    "for word, count in zip(top_words, top_counts):\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just values test\n",
    "unique = np.unique(X_train_vec[2].toarray())\n",
    "print('Unique values:', unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 1-hot BoW\n",
    "+ removing words that occurs less than 3 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts, vocab, selected_words, vectorizer, X_train_hot, X_val_hot = basic_bag(X_train_str, X_val_str, min_refs=2, ohe=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if dataset is binary\n",
    "unique = np.unique(X_train_hot.toarray())\n",
    "print('Unique values:', unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts, vocab, selected_words, vectorizer, X_train_vec_tf, X_val_vec_tf = tf_idf(X_train_str, X_val_str, min_refs=3, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 N-grams\n",
    "\n",
    "### 5.4.1 Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts, vocab, selected_words, vectorizer, X_train_vec_bi, X_val_vec_bi = basic_bag(X_train_str, X_val_str, ngram_range=(2,2), min_refs=2, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_vocab = vectorizer.get_feature_names_out()\n",
    "bigram_counts = np.asarray(X_train_vec_bi.sum(axis=0)).flatten()\n",
    "\n",
    "bigram_freq = list(zip(bigram_vocab, bigram_counts))\n",
    "\n",
    "# Soritng\n",
    "sorted_bigram_freq = sorted(bigram_freq, key=lambda x: x[1], reverse=True)\n",
    "print(\"10 most common bigrams:\\n\")\n",
    "for bigram, count in sorted_bigram_freq[:10]:\n",
    "    print(f\"{bigram}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Words Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Own Word2Vec Model (CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model1 = word2vec_alg(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity between tokens\n",
    "try:\n",
    "    similarity_tokens = word2vec_model1.wv.similarity('cat', 'dog')\n",
    "    print(f\"Similarity: {similarity_tokens:.4f}\")\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Most similar words to the specific token\n",
    "try:\n",
    "    similar_words_token = word2vec_model1.wv.most_similar('dog', topn=5)\n",
    "    print(\"Most similar words:\", similar_words_token)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Token which doesn't match (Odd-One-Out)\n",
    "try: \n",
    "    not_match_token = word2vec_model1.wv.doesnt_match(['cat','dog','wine'])\n",
    "    print('Not matching word:', not_match_token)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Perform an analogy task\n",
    "try:\n",
    "    analogy_result = word2vec_model1.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "    print(\"Analogy result:\", analogy_result)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique words in the Word2vec Model:',len(word2vec_model1.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "# List of words that we want to display\n",
    "words_to_explore= ['woman', 'man', 'queen', 'king', 'human', 'person', 'girl', 'child', 'boy', 'salad', 'lettuce', 'tomato', 'soup', 'turnip', 'arugula', 'pepper', 'greens', 'barley', 'bean', 'stew', 'carrot']\n",
    "visualize_word_embeddings(word2vec_model1, words_to_explore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Own Word2Vec Model (Skip Gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model2 = word2vec_alg(X_train, sg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity between tokens\n",
    "try:\n",
    "    similarity_tokens = word2vec_model2.wv.similarity('cat', 'dog')\n",
    "    print(f\"Similarity: {similarity_tokens:.4f}\")\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Most similar words to the specific token\n",
    "try:\n",
    "    similar_words_token = word2vec_model2.wv.most_similar('dog', topn=5)\n",
    "    print(\"Most similar words:\", similar_words_token)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Token which doesn't match (Odd-One-Out)\n",
    "try: \n",
    "    not_match_token = word2vec_model2.wv.doesnt_match(['cat','dog','wine'])\n",
    "    print('Not matching word:', not_match_token)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Perform an analogy task\n",
    "try:\n",
    "    analogy_result = word2vec_model2.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "    print(\"Analogy result:\", analogy_result)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "# List of words that we want to display\n",
    "words_to_explore= ['woman', 'man', 'queen', 'king', 'human', 'person', 'girl', 'child', 'boy', 'salad', 'lettuce', 'tomato', 'soup', 'turnip', 'arugula', 'pepper', 'greens', 'barley', 'bean', 'stew', 'carrot']\n",
    "visualize_word_embeddings(word2vec_model2, words_to_explore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Fine-Tuning Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and covert pretrained model\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(\"model/glove.6B.100d.txt\", \"model/glove_model2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model3 = word2vec_alg(X_train, pretrained_path='model/glove_model2.txt', sg=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity between tokens\n",
    "try:\n",
    "    similarity_tokens = word2vec_model3.wv.similarity('cat', 'dog')\n",
    "    print(f\"Similarity: {similarity_tokens:.4f}\")\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Most similar words to the specific token\n",
    "try:\n",
    "    similar_words_token = word2vec_model3.wv.most_similar('dog', topn=5)\n",
    "    print(\"Most similar words:\", similar_words_token)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Token which doesn't match (Odd-One-Out)\n",
    "try: \n",
    "    not_match_token = word2vec_model3.wv.doesnt_match(['wine','beer','clock'])\n",
    "    print('Not matching word:', not_match_token)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Perform an analogy task\n",
    "try:\n",
    "    analogy_result = word2vec_model3.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "    print(\"Analogy result:\", analogy_result)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique words in the Word2vec Model:',len(word2vec_model3.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "# List of words that we want to display\n",
    "words_to_explore= ['woman', 'man', 'queen', 'king', 'human', 'person', 'girl', 'child', 'boy', 'salad', 'lettuce', 'tomato', 'soup', 'turnip', 'arugula', 'pepper', 'greens', 'barley', 'bean', 'stew', 'carrot']\n",
    "visualize_word_embeddings(word2vec_model3, words_to_explore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train = combined_sentiment_df.text.astype(str).tolist()\n",
    "y_train = combined_sentiment_df.sentiment_label\n",
    "X_val = combined_sentiment_df_val.text.astype(str).tolist()\n",
    "y_val = combined_sentiment_df_val.sentiment_label\n",
    "\n",
    "# # Generate embeddings\n",
    "X_train_vec, X_val_vec = bert_embeddings(X_train, X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_sentiment_df = pd.read_csv(\"data_sentiment_preprocessed.csv\")\n",
    "combined_sentiment_df_val = pd.read_csv(\"data_sentiment_preprocessed_val.csv\")\n",
    "\n",
    "from our_feature_extraction import basic_bag, tf_idf\n",
    "# Split the data\n",
    "X_train = combined_sentiment_df.tokenized_text\n",
    "y_train = combined_sentiment_df.sentiment_label\n",
    "X_val = combined_sentiment_df_val.tokenized_text\n",
    "y_val = combined_sentiment_df_val.sentiment_label\n",
    "word_counts, vocab, selected_words, vectorizer, X_train_vec, X_val_vec = basic_bag(X_train, X_val, ohe=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from our_feature_selection import *\n",
    "\n",
    "print(X_train_vec.shape)\n",
    "sel, X_train_redux, X_test_redux = feat_filtering(X_train_vec, y_train, X_val_vec)\n",
    "print(X_train_redux.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel, X_train_rfe, X_test_rfe = rfe(X_train_vec, y_train, X_val_vec)\n",
    "print(X_train_rfe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb(X_train_vec, X_val_vec, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb(X_train_rfe, X_test_rfe, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb(X_train_redux, X_test_redux, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Basic BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb(X_train_vec, X_val_vec, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 1-hot BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb(X_train_hot, X_val_hot, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb(X_train_vec_tf, X_val_vec_tf, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb(X_train_vec_bi, X_val_vec_bi, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Basic BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine(X_train_vec, X_val_vec, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 1-hot BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine(X_train_hot, X_val_hot, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine(X_train_vec_tf, X_val_vec_tf, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine(X_train_vec_bi, X_val_vec_bi, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Basic BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(X_train_vec, X_val_vec, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 1-hot BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(X_train_hot, X_val_hot, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(X_train_vec_tf, X_val_vec_tf, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(X_train_vec_bi, X_val_vec_bi, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Embedding Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_vec)\n",
    "X_val_scaled = scaler.transform(X_val_vec)\n",
    "\n",
    "\n",
    "nb(X_train_scaled, X_val_scaled, y_train, y_val)\n",
    "\n",
    "sel, X_train_redux, X_val_redux = feat_filtering(X_train_scaled, y_train, X_val_scaled, k=2)\n",
    "\n",
    "nb(X_train_redux, X_val_redux, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_vec)\n",
    "X_val_scaled = scaler.transform(X_val_vec)\n",
    "\n",
    "support_vector_machine(X_train_scaled, X_val_scaled, y_train, y_val) # Best Parameters:  {'C': 100, 'gamma': 0.01, 'kernel': 'sigmoid'} for bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from our_feature_selection import rfe\n",
    "\n",
    "rfe(X_train_vec, y_train, X_val_vec, min_features_to_select=int(X_train_vec.shape[1]*0.9), save_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./rfecv_svm.pickle', \"rb\") as f:\n",
    "    rfe_sel = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "best_model = SVC(C=100, gamma=0.01, kernel='sigmoid')\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "sel, X_train_redux, X_val_redux = feat_filtering(X_train_scaled, y_train, X_val_vec, k=95)\n",
    "best_model.fit(X_train_redux, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_val_redux)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "X_train_redux = rfe_sel.transform(X_train_scaled)\n",
    "X_val_redux = rfe_sel.transform(X_val_scaled)\n",
    "best_model.fit(X_train_redux, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_val_redux)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_vec)\n",
    "X_val_scaled = scaler.transform(X_val_vec)\n",
    "\n",
    "\n",
    "best_model = LogisticRegression(max_iter=5)\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "y_pred = best_model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_vec, y_train)\n",
    "y_pred = rf.predict(X_val_vec)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(X_train_vec, X_val_vec, y_train, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
