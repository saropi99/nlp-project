{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Sentiment Analysis Classifier\n",
    "\n",
    "##### Group 26: Michal Dawid Kowalski (up202401554) | Pedro Maria Passos Ribeiro do Carmo Pereira (up201708807) | Santiago Romero Pineda (up)\n",
    "\n",
    "In this assignment, we will build a sentiment analysis classifier using traditional machine learning techniques. The process includes pre-processing, feature extraction, and exploring both sparse and dense feature representations like word embeddings. We will use \"traditional\" machine learning classifier instead of deep learning models (CNNs, RNNs, Transformers). The focus will be on understanding text classification techniques and evaluating their performance on the given dataset using common classification metrics like accuracy, precision, recall, and F1-score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from our_eda import *\n",
    "from our_modeling import *\n",
    "from common.our_preprocessing import *\n",
    "from our_feature_extraction import *\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from our_feature_selection import *\n",
    "import gensim.downloader as api\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. BESSTIE Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Uploading Dataset Files from HuggingFace (https://huggingface.co/mindhunter23)\n",
    "\n",
    "The dataset is hosted on Hugging Face under the username \"mindhunter23.\" It consists of text data collected from Reddit and Google for the countries UK, AU, and IN. All texts are in English and are labeled with sentiment values: 0 for negative sentiment and 1 for positive sentiment. The dataset is already split into training and validation sets, making it ready for sentiment analysis tasks. It offers diverse content from different regions and platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BESSTIE-reddit-sentiment-uk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'reddit-sentiment-uk-train.jsonl', 'validation': 'reddit-sentiment-uk-valid.jsonl'}\n",
    "df_reddit_sentiment_uk = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-reddit-sentiment-uk/\" + splits[\"train\"], lines=True)\n",
    "df_reddit_sentiment_uk_val = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-reddit-sentiment-uk/\" + splits[\"validation\"], lines=True)\n",
    "df_reddit_sentiment_uk.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training CLasses Distribution\\n')\n",
    "print(class_distribution(df_reddit_sentiment_uk))\n",
    "print('Validation CLasses Distribution\\n')\n",
    "print(class_distribution(df_reddit_sentiment_uk_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BESSTIE-reddit-sentiment-au/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'reddit-sentiment-au-train.jsonl', 'validation': 'reddit-sentiment-au-valid.jsonl'}\n",
    "df_reddit_sentiment_au = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-reddit-sentiment-au/\" + splits[\"train\"], lines=True)\n",
    "df_reddit_sentiment_au_val = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-reddit-sentiment-au/\" + splits[\"validation\"], lines=True)\n",
    "df_reddit_sentiment_au.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training CLasses Distribution\\n')\n",
    "print(class_distribution(df_reddit_sentiment_au))\n",
    "print('Validation CLasses Distribution\\n')\n",
    "print(class_distribution(df_reddit_sentiment_au_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BESSTIE-google-sentiment-uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'google-sentiment-uk-train.jsonl', 'validation': 'google-sentiment-uk-valid.jsonl'}\n",
    "df_google_sentiment_uk = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-google-sentiment-uk/\" + splits[\"train\"], lines=True)\n",
    "df_google_sentiment_uk_val = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-google-sentiment-uk/\" + splits[\"validation\"], lines=True)\n",
    "df_google_sentiment_uk.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training CLasses Distribution\\n')\n",
    "print(class_distribution(df_google_sentiment_uk))\n",
    "print('Validation CLasses Distribution\\n')\n",
    "print(class_distribution(df_google_sentiment_uk_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BESSTIE-google-sentiment-au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'data/google-sentiment-au-train.jsonl', 'validation': 'data/google-sentiment-au-valid.jsonl'}\n",
    "df_google_sentiment_au = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-google-sentiment-au/\" + splits[\"train\"], lines=True)\n",
    "df_google_sentiment_au_val = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-google-sentiment-au/\" + splits[\"validation\"], lines=True)\n",
    "df_google_sentiment_au.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training CLasses Distribution\\n')\n",
    "print(class_distribution(df_google_sentiment_au))\n",
    "print('Validation CLasses Distribution\\n')\n",
    "print(class_distribution(df_google_sentiment_au_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BESSTIE-reddit-sentiment-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'reddit-sentiment-in-train.jsonl', 'validation': 'reddit-sentiment-in-valid.jsonl'}\n",
    "df_reddit_sentiment_in = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-reddit-sentiment-in/\" + splits[\"train\"], lines=True)\n",
    "df_reddit_sentiment_in_val = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-reddit-sentiment-in/\" + splits[\"validation\"], lines=True)\n",
    "df_reddit_sentiment_in.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training CLasses Distribution\\n')\n",
    "print(class_distribution(df_reddit_sentiment_in))\n",
    "print('Validation CLasses Distribution\\n')\n",
    "print(class_distribution(df_reddit_sentiment_in_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BESSTIE-google-sentiment-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'google-sentiment-in-train.jsonl', 'validation': 'google-sentiment-in-valid.jsonl'}\n",
    "df_google_sentiment_in = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-google-sentiment-in/\" + splits[\"train\"], lines=True)\n",
    "df_google_sentiment_in_val = pd.read_json(\"hf://datasets/mindhunter23/BESSTIE-google-sentiment-in/\" + splits[\"validation\"], lines=True)\n",
    "df_google_sentiment_in.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training CLasses Distribution\\n')\n",
    "print(class_distribution(df_google_sentiment_in))\n",
    "print('Validation CLasses Distribution\\n')\n",
    "print(class_distribution(df_google_sentiment_in_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Initial Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Testing text_preprocess() func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the preprocessing function \n",
    "print('Original:\\n', df_reddit_sentiment_uk.loc[0].text,'\\n')\n",
    "print('Lemmatization:\\n',text_preprocess(df_reddit_sentiment_uk.loc[0].text, remove_digits=True, stemmer=Stemmer.WordNet),'\\n')\n",
    "print('Stemming:\\n',text_preprocess(df_reddit_sentiment_uk.loc[0].text),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Concatening datasets into single Dataframe\n",
    "### SENTIMENT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assue all datasets are already loaded as DataFrames\n",
    "combined_sentiment_df = pd.concat(\n",
    "    [\n",
    "        df_reddit_sentiment_uk,\n",
    "        df_reddit_sentiment_au,\n",
    "        df_google_sentiment_uk,\n",
    "        df_google_sentiment_au,\n",
    "        df_reddit_sentiment_in,\n",
    "        df_google_sentiment_in\n",
    "    ],\n",
    "    axis=0,  # Concatenate vertically (row-wise)\n",
    "    ignore_index=True  # Reset the index in the combined DataFrame\n",
    ")\n",
    "\n",
    "# Assue all datasets are already loaded as DataFrames\n",
    "combined_sentiment_df_val = pd.concat(\n",
    "    [\n",
    "        df_reddit_sentiment_uk_val,\n",
    "        df_reddit_sentiment_au_val,\n",
    "        df_google_sentiment_uk_val,\n",
    "        df_google_sentiment_au_val,\n",
    "        df_reddit_sentiment_in_val,\n",
    "        df_google_sentiment_in_val\n",
    "    ],\n",
    "    axis=0,  # Concatenate vertically (row-wise)\n",
    "    ignore_index=True  # Reset the index in the combined DataFrame\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined data\n",
    "combined_sentiment_df.to_csv(\"../common/data_sentiment_preprocessed.csv\", index=False)\n",
    "combined_sentiment_df_val.to_csv(\"../common/data_sentiment_preprocessed_val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional, when already have necessary data files\n",
    "# combined_sentiment_df = pd.read_csv(\"../common/data_sentiment_preprocessed.csv\")\n",
    "# combined_sentiment_df_val = pd.read_csv(\"../common/data_sentiment_preprocessed_val.csv\")\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(f\"Total rows in combined training dataset: {len(combined_sentiment_df)}\\n\")\n",
    "print('\\nClasses Distribution in Training Dataset:\\n')\n",
    "class_distribution(combined_sentiment_df)\n",
    "print('\\n')\n",
    "plt.figure(figsize=(6,4))\n",
    "combined_sentiment_df['sentiment_label'].value_counts().plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution of Sentiment Labels (Training)')\n",
    "plt.xlabel('Sentiment Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "print(\"Training Dataset:\\n\")\n",
    "combined_sentiment_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the combined DataFrame\n",
    "print(f\"Total rows in combined validation dataset: {len(combined_sentiment_df_val)}\\n\")\n",
    "print('\\nClasses Distribution in Validation Dataset:\\n')\n",
    "class_distribution(combined_sentiment_df)\n",
    "print('\\n')\n",
    "plt.figure(figsize=(6,4))\n",
    "combined_sentiment_df_val['sentiment_label'].value_counts().plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution of Sentiment Labels (Validation)')\n",
    "plt.xlabel('Sentiment Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "print(\"Validation Dataset:\\n\")\n",
    "combined_sentiment_df_val.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of characters per review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "combined_sentiment_df['text'].str.len().hist(bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Text Length (Character Count)', fontsize=12)\n",
    "plt.xlabel('Character Count', fontsize=10)\n",
    "plt.ylabel('Sample Count', fontsize=10)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax1.hist(combined_sentiment_df[combined_sentiment_df['sentiment_label'] == 1]['text'].str.len(), bins=50, color='skyblue', edgecolor='black')\n",
    "ax1.set_title('Positive Reviews', fontsize=12)\n",
    "ax1.set_xlabel('Character Count', fontsize=10)\n",
    "ax1.set_ylabel('Sample Count', fontsize=10)\n",
    "ax1.tick_params(axis='both', labelsize=8)\n",
    "ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "ax2.hist(combined_sentiment_df[combined_sentiment_df['sentiment_label'] == 0]['text'].str.len(), bins=50, color='skyblue', edgecolor='black')\n",
    "ax2.set_title('Negative Reviews', fontsize=12)\n",
    "ax2.set_xlabel('Character Count', fontsize=10)\n",
    "ax2.set_ylabel('Sample Count', fontsize=10)\n",
    "ax2.tick_params(axis='both', labelsize=8)\n",
    "ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSITIVE SENTIMENT WODDCLOUD\n",
    "text = \" \".join(i for i in combined_sentiment_df[combined_sentiment_df['sentiment_label']==1]['text'])\n",
    "wordcloud = WordCloud(background_color=\"white\").generate(text)\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Wordcloud for positive reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEGATIVE SENTIMENT WORDCLOUD\n",
    "text = \" \".join(i for i in combined_sentiment_df[combined_sentiment_df['sentiment_label']==0]['text'])\n",
    "wordcloud = WordCloud( background_color=\"white\").generate(text)\n",
    "\n",
    "plt.figure( figsize=(14,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Wordcloud for negative reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Text Preprocessing\n",
    "\n",
    "The `text_preprocess()` function in the `_preprocessing.py` file applies several essential text preprocessing techniques to prepare the data for further analysis and modeling:\n",
    "\n",
    "- **Convert to Lowercase**: Transforms all text to lowercase to ensure uniformity.\n",
    "- **Remove URLs and Emails**: Eliminates any URLs and email addresses found in the text.\n",
    "- **Remove Digits**: Removes any numeric characters that might not be relevant for the analysis.\n",
    "- **Correct Misspellings**: Automatically detects and corrects spelling mistakes to improve text quality.\n",
    "- **Expand Contractions**: Expands common contractions (e.g., \"can't\" to \"cannot\", \"i'm\" to \"i am\") for consistency in the text.\n",
    "- **Lemmatization (optional: Stemming)**: Performs part-of-speech tagging and lemmatization using the `lemm_text()` function, reducing words to their base or root forms.\n",
    "- **Remove Stopwords**: Removes stopwords, with the option to retain negations for preserving sentiment (optional flag to enable/disable this).\n",
    "- **Delete Punctuation**: Strips away punctuation marks that do not contribute to the analysis.\n",
    "- **Remove Extra Spaces**: Cleans up extra spaces, including leading and trailing spaces, to normalize the text.\n",
    "\n",
    "These preprocessing techniques ensure that the text data is clean, consistent, and ready for feature extraction or modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing + Lemmatization \n",
    "combined_sentiment_df['clean_text'] = combined_sentiment_df['text'].apply(lambda x: text_preprocess(x, remove_digits=True, stemmer=Stemmer.WordNet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "combined_sentiment_df['tokenized_text'] = combined_sentiment_df['clean_text'].apply(lambda x: word_tokenize(x))\n",
    "combined_sentiment_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed training data\n",
    "combined_sentiment_df.to_csv('data_sentiment_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing + Lemmatization \n",
    "combined_sentiment_df_val['clean_text'] = combined_sentiment_df_val['text'].apply(lambda x: text_preprocess(x, remove_digits=True, stemmer=Stemmer.WordNet))\n",
    "# Tokenization\n",
    "combined_sentiment_df_val['tokenized_text'] = combined_sentiment_df_val['clean_text'].apply(lambda x: word_tokenize(x))\n",
    "combined_sentiment_df_val.head(5)\n",
    "# Save preprocessed validation data\n",
    "combined_sentiment_df_val.to_csv('data_sentiment_preprocessed_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:18:18.744734Z",
     "start_time": "2025-03-28T01:18:18.561606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optional, read datasets from files\n",
    "combined_sentiment_df = pd.read_csv('data_sentiment_preprocessed.csv')\n",
    "combined_sentiment_df_val = pd.read_csv('data_sentiment_preprocessed_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Handling possible Missing Values after text preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:18:20.641022Z",
     "start_time": "2025-03-28T01:18:20.615452Z"
    }
   },
   "outputs": [],
   "source": [
    "print(combined_sentiment_df.isnull().value_counts())\n",
    "combined_sentiment_df = combined_sentiment_df.dropna() # Drop rows where preprocessing didnt extract any tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:18:21.477582Z",
     "start_time": "2025-03-28T01:18:21.461624Z"
    }
   },
   "outputs": [],
   "source": [
    "print(combined_sentiment_df_val.isnull().value_counts())\n",
    "combined_sentiment_df_val = combined_sentiment_df_val.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:18:24.399435Z",
     "start_time": "2025-03-28T01:18:22.159154Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenization because after reading from the file list with tokens converts into str\n",
    "combined_sentiment_df['tokenized_text'] = combined_sentiment_df['clean_text'].apply(lambda x: word_tokenize(x))\n",
    "combined_sentiment_df_val['tokenized_text'] = combined_sentiment_df_val['clean_text'].apply(lambda x: word_tokenize(x))\n",
    "combined_sentiment_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:18:25.041841Z",
     "start_time": "2025-03-28T01:18:24.472500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check number of unique words before and after the preprocessing\n",
    "all_words = ' '.join(combined_sentiment_df['text']).split()\n",
    "unique_words = set(all_words)\n",
    "\n",
    "all_words_clean = ' '.join(combined_sentiment_df['clean_text']).split()\n",
    "unique_words_clean = set(all_words_clean)\n",
    "\n",
    "labels = ['Unique Words in Raw Text', 'Unique Words in Cleaned Text']\n",
    "sizes = [len(unique_words), len(unique_words_clean)]\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie(sizes, labels=labels, autopct=lambda p: f'{int(p * sum(sizes) / 100)}', startangle=90, colors = ['#FF6347', 'skyblue'])\n",
    "plt.title('Comparison of Unique Words in Raw vs Cleaned Text')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Features Extraction\n",
    "\n",
    "In the `our_feature_extraction.py` file, we implement various techniques for extracting features from the text data. These methods are divided into sparse and dense representations of text, offering flexibility depending on the type of analysis and model being used.\n",
    "\n",
    "#### Sparse Representations\n",
    "\n",
    "- **Bag of Words (BOW)**: A simple method where each document is represented as a vector of word counts, without considering word order. This method creates a sparse matrix of word frequencies.\n",
    "- **One-Hot Encoding (BOW)**: An extension of BOW where each word is represented as a one-hot encoded vector, where each word is mapped to a unique index in the vector.\n",
    "- **TF-IDF (Term Frequency - Inverse Document Frequency)**: A more advanced method than BOW that weighs the words based on their frequency in the document and their rarity across the entire corpus. This technique helps highlight important words in the text.\n",
    "- **Bigrams (O-H)BOW/TF-IDF**: Instead of individual words, this method considers pairs of consecutive words (bigrams) to capture context and word combinations that may provide additional meaning.\n",
    "  \n",
    "  - **Token Frequency Filtering**: For all of the above sparse techniques, there is an option to filter out infrequent or overly common tokens based on their frequency. This allows reducing the dimensionality of the feature space by excluding words that may not contribute significantly to the analysis.\n",
    "\n",
    "#### Dense Representations\n",
    "\n",
    "- **Word2Vec**: A dense representation technique where words are embedded into dense vectors in a continuous vector space. These embeddings are learned by the Word2Vec model, capturing semantic relationships between words based on their context (also Handling Multi Word Expressions)\n",
    "- **BerTopic**: A topic modeling technique based on transformer embeddings, which uses BERT (Bidirectional Encoder Representations from Transformers) embeddings to generate high-quality topics. This technique is useful for extracting meaningful topics from a collection of documents.\n",
    "\n",
    "These feature extraction methods are essential for converting raw text data into numerical representations that can be processed by machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:18:25.231244Z",
     "start_time": "2025-03-28T01:18:25.219552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data info into Train and Test set\n",
    "X_train = combined_sentiment_df.tokenized_text\n",
    "y_train = combined_sentiment_df.sentiment_label\n",
    "X_val = combined_sentiment_df_val.tokenized_text\n",
    "y_val = combined_sentiment_df_val.sentiment_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5.1 Basic BoW\n",
    "+ also removing rare tokens that occurs less than 3 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:20:03.400062Z",
     "start_time": "2025-03-28T01:20:01.894048Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert X_train and X_val into proper type\n",
    "X_train_str = [' '.join(tokens) for tokens in combined_sentiment_df.tokenized_text]\n",
    "\n",
    "X_val_str = [' '.join(tokens) for tokens in combined_sentiment_df_val.tokenized_text]\n",
    "\n",
    "word_counts, vocab, selected_words, vectorizer, X_train_vec, X_val_vec = basic_bag(X_train_str, X_val_str, debug=True, min_refs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:47:39.873428Z",
     "start_time": "2025-03-27T16:47:39.849228Z"
    }
   },
   "outputs": [],
   "source": [
    "# 10 most common words\n",
    "word_counts = np.asarray(X_train_vec.sum(axis=0)).flatten()\n",
    "vocab = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "top_indices = np.argsort(word_counts)[::-1]\n",
    "top_words = vocab[top_indices[:10]]\n",
    "top_counts = word_counts[top_indices[:10]]\n",
    "\n",
    "print('Top 10 most common words:\\n')\n",
    "for word, count in zip(top_words, top_counts):\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:31:09.525846Z",
     "start_time": "2025-03-27T16:31:09.515524Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just values test\n",
    "unique = np.unique(X_train_vec[2].toarray())\n",
    "print('Unique values:', unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5.2 One-Hot Encoding BoW\n",
    "+ also removing rare tokens that occurs less than 3 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T03:23:27.297780Z",
     "start_time": "2025-03-28T03:23:25.983981Z"
    }
   },
   "outputs": [],
   "source": [
    "word_counts, vocab, selected_words, vectorizer, X_train_hot, X_val_hot = basic_bag(X_train_str, X_val_str, min_refs=2, ohe=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T16:31:18.690539Z",
     "start_time": "2025-03-27T16:31:14.918180Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking if dataset is binary\n",
    "unique = np.unique(X_train_hot.toarray())\n",
    "print('Unique values:', unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5.3 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T02:08:31.549717Z",
     "start_time": "2025-03-28T02:08:30.711281Z"
    }
   },
   "outputs": [],
   "source": [
    "# TF-IDF Representation\n",
    "word_counts, vocab, selected_words, vectorizer, X_train_vec_tf, X_val_vec_tf = tf_idf(X_train_str, X_val_str, debug=True, min_refs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.4.1 Bigrams BoW Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:21:00.930768Z",
     "start_time": "2025-03-28T01:20:58.532038Z"
    }
   },
   "outputs": [],
   "source": [
    "word_counts, vocab, selected_words, vectorizer, X_train_vec_bi, X_val_vec_bi = basic_bag(X_train_str, X_val_str, ngram_range=(2,2), debug=True, ohe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T17:55:46.920370Z",
     "start_time": "2025-03-27T17:55:46.877822Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram_vocab = vectorizer.get_feature_names_out()\n",
    "bigram_counts = np.asarray(X_train_vec_bi.sum(axis=0)).flatten()\n",
    "\n",
    "bigram_freq = list(zip(bigram_vocab, bigram_counts))\n",
    "\n",
    "# Sorting bigrams\n",
    "sorted_bigram_freq = sorted(bigram_freq, key=lambda x: x[1], reverse=True)\n",
    "print(\"10 most common bigrams:\\n\")\n",
    "for bigram, count in sorted_bigram_freq[:10]:\n",
    "    print(f\"{bigram}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.4.2 Bigrams TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:22:49.135751Z",
     "start_time": "2025-03-28T01:22:47.176335Z"
    }
   },
   "outputs": [],
   "source": [
    "word_counts, vocab, selected_words, vectorizer, X_train_vec_bi_tf, X_val_vec_bi_tf = tf_idf(X_train_str, X_val_str, ngram_range=(2, 2) , min_refs=2, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Words Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### - Own Word2Vec Model (CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding CBOW\n",
    "word2vec_model1 = w2v_embeddings(X_train, alpha=0.05, vector_size=300, window=10, epochs=20, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity between tokens\n",
    "try:\n",
    "    similarity_tokens = word2vec_model1.wv.similarity('cat', 'dog')\n",
    "    print(f\"Similarity: {similarity_tokens:.4f}\")\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Most similar words to the specific token\n",
    "try:\n",
    "    similar_words_token = word2vec_model1.wv.most_similar('cat', topn=5)\n",
    "    print(\"Most similar words:\", similar_words_token)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Token which doesn't match (Odd-One-Out)\n",
    "try: \n",
    "    not_match_token = word2vec_model1.wv.doesnt_match(['cat','dog','juice'])\n",
    "    print('Not matching word:', not_match_token)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Perform an analogy task\n",
    "try:\n",
    "    analogy_result = word2vec_model1.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "    print(\"Analogy result:\", analogy_result)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique words in the Word2vec Model:',len(word2vec_model1.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "# List of words that we want to display\n",
    "words_to_explore= ['good','place','great','staff','nice','service','time','restaurant','one','will','food','time','need','even','place']\n",
    "visualize_word_embeddings(word2vec_model1, words_to_explore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "X_train_vec_w2v, X_val_vec_w2v = w2v_embeddings_split(X_train, X_val, word2vec_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### - Own Word2Vec Model (Skip Gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model2 = w2v_embeddings(X_train, sg=True, alpha=0.05, vector_size=300, window=5, epochs=50, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity between tokens\n",
    "try:\n",
    "    similarity_tokens = word2vec_model2.wv.similarity('cat', 'dog')\n",
    "    print(f\"Similarity: {similarity_tokens:.4f}\")\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Most similar words to the specific token\n",
    "try:\n",
    "    similar_words_token = word2vec_model2.wv.most_similar('dog', topn=10)\n",
    "    print(\"Most similar words:\", similar_words_token)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Token which doesn't match (Odd-One-Out)\n",
    "try: \n",
    "    not_match_token = word2vec_model2.wv.doesnt_match(['cat','dog','wine'])\n",
    "    print('Not matching word:', not_match_token)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "\n",
    "# Perform an analogy task\n",
    "try:\n",
    "    analogy_result = word2vec_model2.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "    print(\"Analogy result:\", analogy_result)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "# List of words that we want to display\n",
    "words_to_explore= ['good','place','great','staff','nice','service','time','restaurant','one','will','food','time','need','even','place']\n",
    "visualize_word_embeddings(word2vec_model2, words_to_explore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "X_train_vec_w2v, X_val_vec_w2v = w2v_embeddings_split(X_train, X_val, word2vec_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### - Bert Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train = combined_sentiment_df.text.astype(str).tolist()\n",
    "y_train = combined_sentiment_df.sentiment_label\n",
    "X_val = combined_sentiment_df_val.text.astype(str).tolist()\n",
    "y_val = combined_sentiment_df_val.sentiment_label\n",
    "\n",
    "# Generate embeddings\n",
    "# X_train_vec, X_val_vec = bert_embeddings_split(X_train, X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Feature Selection\n",
    "\n",
    "The following methods are used to reduce the dimensionality of the dataset by selecting the most relevant features:\n",
    "\n",
    "- **feat_filtering()**  \n",
    "  Performs feature selection using statistical tests:\n",
    "  - **Method**: Select top `k` features (`'k'`) or top `k` percentile (`'percentile'`).\n",
    "  - **Functions**: Uses `'chi2'`, `'f'`, or `'mutual_info'` to score features.\n",
    "\n",
    "- **rfe()**  \n",
    "  Uses Recursive Feature Elimination with Cross-Validation (RFECV) to iteratively remove less important features based on model performance, finding the optimal feature set.\n",
    "  - Supports models like `'svm'`, `'logistic'`, and `'rf'`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from our_feature_extraction import basic_bag, tf_idf\n",
    "# Split the data\n",
    "X_train = combined_sentiment_df.tokenized_text\n",
    "y_train = combined_sentiment_df.sentiment_label\n",
    "X_val = combined_sentiment_df_val.tokenized_text\n",
    "y_val = combined_sentiment_df_val.sentiment_label\n",
    "word_counts, vocab, selected_words, vectorizer, X_train_vec, X_val_vec = basic_bag(X_train, X_val, ohe=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T17:03:57.997052Z",
     "start_time": "2025-03-27T17:03:57.881632Z"
    }
   },
   "outputs": [],
   "source": [
    "from our_feature_selection import *\n",
    "# Features Selection using Chi2\n",
    "print(X_train_vec.shape)\n",
    "sel, X_train_redux, X_test_redux = feat_filtering(X_train_vec, y_train, X_val_vec)\n",
    "print(X_train_redux.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE Features Selectiton\n",
    "sel, X_train_rfe, X_test_rfe = rfe(X_train_vec, y_train, X_val_vec)\n",
    "print(X_train_rfe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Modeling\n",
    "\n",
    "In this step, we evaluate several machine learning models to classify the data. Below are the methods used for training and evaluation:\n",
    "\n",
    "- **Support Vector Machine (SVM)**  \n",
    "  The `support_vector_machine()` function applies a Support Vector Classifier (SVC) with hyperparameter tuning using Grid Search. The parameters tuned include:\n",
    "  - `C` (regularization parameter)\n",
    "  - `kernel` (type of kernel: linear, rbf, poly, sigmoid)\n",
    "  - `gamma` (kernel coefficient)\n",
    "  \n",
    "  The function uses cross-validation (`cv=5`) and reports the best parameters, best cross-validation accuracy, and the classification report with accuracy for the validation set.\n",
    "\n",
    "- **Naive Bayes (NB)**  \n",
    "  The `nb()` function uses the Multinomial Naive Bayes model to classify the data. After fitting the model, predictions are made on the validation set, and the performance is evaluated using accuracy, classification report, and confusion matrix.\n",
    "\n",
    "- **Random Forest** (Skipped)  \n",
    "  Although the `random_forest()` function was prepared for training a Random Forest model with hyperparameter tuning (using grid search for parameters like `n_estimators`, `max_depth`, etc.), we decided to skip the random forest model in this case due to the large number of tests involved.\n",
    "\n",
    "These models are evaluated on their ability to classify the data based on the training and validation sets. We focus on SVM and Naive Bayes for our final model selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7.1 Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### - Basic BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic BoW\n",
    "nb(X_train_vec, X_val_vec, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### - 1-hot BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T00:41:21.071006Z",
     "start_time": "2025-03-28T00:41:21.034317Z"
    }
   },
   "outputs": [],
   "source": [
    "nb(X_train_hot, X_val_hot, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:19:21.596099Z",
     "start_time": "2025-03-28T01:19:21.554496Z"
    }
   },
   "outputs": [],
   "source": [
    "nb(X_train_vec_tf, X_val_vec_tf, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### - Bigrams Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:21:13.635675Z",
     "start_time": "2025-03-28T01:21:13.585907Z"
    }
   },
   "outputs": [],
   "source": [
    "nb(X_train_vec_bi, X_val_vec_bi, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### - Bigrams TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T01:22:58.947666Z",
     "start_time": "2025-03-28T01:22:58.923453Z"
    }
   },
   "outputs": [],
   "source": [
    "nb(X_train_vec_bi_tf, X_val_vec_bi_tf, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7.2 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Basic BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine(X_train_vec, X_val_vec, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### - 1-hot BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T04:01:22.065150Z",
     "start_time": "2025-03-28T03:23:47.020838Z"
    }
   },
   "outputs": [],
   "source": [
    "support_vector_machine(X_train_hot, X_val_hot, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T02:04:26.570805Z",
     "start_time": "2025-03-28T01:25:42.533670Z"
    }
   },
   "outputs": [],
   "source": [
    "support_vector_machine(X_train_vec_tf, X_val_vec_tf, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### - Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine(X_train_vec_bi, X_val_vec_bi, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### - Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec CBOW Best Parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
    "\n",
    "support_vector_machine(X_train_vec_w2v, X_val_vec_w2v, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7.3 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Basic BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(X_train_vec, X_val_vec, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 1-hot BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(X_train_hot, X_val_hot, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(X_train_vec_tf, X_val_vec_tf, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(X_train_vec_bi, X_val_vec_bi, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Embedding Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_vec)\n",
    "X_val_scaled = scaler.transform(X_val_vec)\n",
    "\n",
    "\n",
    "nb(X_train_scaled, X_val_scaled, y_train, y_val)\n",
    "\n",
    "sel, X_train_redux, X_val_redux = feat_filtering(X_train_scaled, y_train, X_val_scaled, k=2)\n",
    "\n",
    "nb(X_train_redux, X_val_redux, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_vec)\n",
    "X_val_scaled = scaler.transform(X_val_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine(X_train_scaled, X_val_scaled, y_train, y_val) # Best Parameters:  {'C': 100, 'gamma': 0.01, 'kernel': 'sigmoid'} for bert , but actually it doesn't really matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from our_feature_selection import rfe\n",
    "\n",
    "rfe(X_train_vec, y_train, X_val_vec, min_features_to_select=int(X_train_vec.shape[1]*0.9), save_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./rfecv_svm.pickle', \"rb\") as f:\n",
    "    rfe_sel = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "best_model = Pipeline([('scaler', MinMaxScaler()), ('svc', SVC(probability=True))])\n",
    "best_model.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_val_vec)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "# sel, X_train_redux, X_val_redux = feat_filtering(X_train_scaled, y_train, X_val_vec, k=95)\n",
    "# best_model.fit(X_train_redux, y_train)\n",
    "\n",
    "# y_pred = best_model.predict(X_val_redux)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_val, y_pred))\n",
    "# print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "# X_train_redux = rfe_sel.transform(X_train_scaled)\n",
    "# X_val_redux = rfe_sel.transform(X_val_scaled)\n",
    "# best_model.fit(X_train_redux, y_train)\n",
    "\n",
    "# y_pred = best_model.predict(X_val_redux)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_val, y_pred))\n",
    "# print(\"Accuracy:\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./best_model.pickle', \"wb\") as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Error Analysis\n",
    "\n",
    "We use **LIME** (Local Interpretable Model-Agnostic Explanations) to interpret the predictions of our model. The `explain_point_label()` function provides a detailed explanation of individual predictions by displaying the most important features. We identify misclassifications with `find_errors()`, then explain a random sample of these errors to better understand the model's behavior and potential weaknesses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./best_model.pickle', \"rb\") as f:\n",
    "    best_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer()\n",
    "\n",
    "def explain_point_label(explainer, predict, pt, num_features=10, num_samples=20):\n",
    "\n",
    "  explanation = explainer.explain_instance(\n",
    "      pt,\n",
    "      predict,\n",
    "      num_features=5,  # Number of words to display as important\n",
    "      num_samples=50,  # Number of perturbations to create\n",
    "  )\n",
    "  explanation.show_in_notebook(text=True)\n",
    "  return explanation\n",
    "\n",
    "def predict_lime(pt):\n",
    "  dings = bert_embeddings(pt)\n",
    "  pred = best_model.predict_proba(dings)\n",
    "  return pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_errors(model, X_val, y_val):\n",
    "    errors = []\n",
    "    i = 0\n",
    "    for row, label in zip(X_val, y_val):\n",
    "        i += 1\n",
    "        pred = predict_lime([row])\n",
    "        if np.argmax(pred) != label:\n",
    "            errors.append(row)\n",
    "\n",
    "    return errors\n",
    "\n",
    "errors = find_errors(best_model, X_val, y_val)\n",
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df.to_json('./errors.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_to_explain = error_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_sample(sample, explainer, predict, num_features=10, num_samples=10):\n",
    "    for i, row in sample.iterrows():\n",
    "        print(row[0])\n",
    "        explain_point_label(explainer, predict, row[0], num_features=num_features, num_samples=num_samples)\n",
    "\n",
    "explain_sample(errors_to_explain, explainer, predict_lime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
