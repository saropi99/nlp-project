{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b84bcd",
   "metadata": {},
   "source": [
    " Employ [Hugging Face](https://huggingface.co/models?pipeline_tag=text-classification&sort=trending&search=sentiment) transformers for the same classification task as in the first assignment.\n",
    "\n",
    "Explore Hugging Face models to find a pre-trained model that is suitable and promising for fine-tuning to your task. It should make sense to pick one that has been pre-trained for the same language and/or text genre.\n",
    "\n",
    "As a bonus, you can also employ a [domain adaptation](https://huggingface.co/learn/llm-course/chapter7/3?fw=pt) approach, explore [parameter-efficient fine-tuning](https://huggingface.co/docs/peft/main/quicktour) (e.g. LoRA), or [prompting language models](https://huggingface.co/docs/transformers/v4.49.0/en/tasks/prompting).\n",
    "\n",
    "We must ompare the performance of your model(s) with the ones developed for the first assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c560a55d",
   "metadata": {},
   "source": [
    "Most of the models have problems processing the text!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2ec1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import CustomDataset, CustomDataset1\n",
    "from datasets import Dataset, load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline, EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 fold\n",
    "train_ds = load_dataset(\"csv\", data_files={\"train\": \"../common/data_sentiment_preprocessed.csv\"}, split=[f\"train[:{k}%]+train[{k+10}%:]\" for k in range(0, 100, 20)])\n",
    "val_ds = load_dataset(\"csv\", data_files=[\"../common/data_sentiment_preprocessed_val.csv\"], split=[f\"train[:{k}%]+train[{k+10}%:]\" for k in range(0, 100, 20)])\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(p.label_ids, preds),\n",
    "        \"f1\": f1_score(p.label_ids, preds),\n",
    "    }\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    global tokenizer\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "def tokenize_datasets(train_ds, val_ds, preprocess_function):\n",
    "    for idx, item in enumerate(train_ds):\n",
    "        train_ds[idx] = item.rename_column(\"sentiment_label\", \"label\")\n",
    "        train_ds[idx] = train_ds[idx].map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            desc=\"Running tokenizer on dataset\",\n",
    "        )\n",
    "\n",
    "    for idx, item in enumerate(val_ds):\n",
    "        val_ds[idx] = item.rename_column(\"sentiment_label\", \"label\")\n",
    "        val_ds[idx] = val_ds[idx].map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            desc=\"Running tokenizer on dataset\",\n",
    "        )\n",
    "\n",
    "def model_init():\n",
    "    global model_path\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "\n",
    "def run_cross_validation(train_ds, val_ds, model_init, tokenizer, model_name):\n",
    "    tokenize_datasets(train_ds, val_ds, tokenize_function)\n",
    "\n",
    "    accuracies = []\n",
    "    f1s = []\n",
    "\n",
    "    for i in range(len(train_ds)):\n",
    "        print(f\"Running fold {i+1}/{len(train_ds)}\")\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f\"./results/{model_name}/fold_{i}\",\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=64,\n",
    "            num_train_epochs=10,  # Give room for early stopping\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            logging_dir=f\"./logs/fold_{i}\",\n",
    "            logging_steps=10,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",  # Use F1 for early stopping\n",
    "            greater_is_better=True,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model_init=model_init,\n",
    "            args=training_args,\n",
    "            train_dataset=train_ds[i],\n",
    "            eval_dataset=val_ds[i],\n",
    "            compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        metrics = trainer.evaluate()\n",
    "\n",
    "        accuracies.append(metrics[\"eval_accuracy\"])\n",
    "        f1s.append(metrics[\"eval_f1\"])\n",
    "\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1s)\n",
    "\n",
    "    print(f\"\\nAverage Accuracy: {avg_accuracy:.4f}\")\n",
    "    print(f\"Average F1 Score: {avg_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63a73390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'text', 'sentiment_label', 'clean_text', 'tokenized_text'],\n",
       "    num_rows: 7980\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "972a2bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99de155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_sentiment_df = pd.read_csv(\"../common/data_sentiment_preprocessed.csv\")\n",
    "combined_sentiment_df_val = pd.read_csv(\"../common/data_sentiment_preprocessed_val.csv\")\n",
    "x_train = combined_sentiment_df.text\n",
    "y_train = combined_sentiment_df.sentiment_label\n",
    "x_val = combined_sentiment_df_val.text\n",
    "y_val = combined_sentiment_df_val.sentiment_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c4d1f",
   "metadata": {},
   "source": [
    "## Making use of pretrained huggingface models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee1c04a",
   "metadata": {},
   "source": [
    "### siebert/sentiment-roberta-large-english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "badf0cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9987329840660095}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9992897510528564}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9969078898429871}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#https://huggingface.co/siebert/sentiment-roberta-large-english?library=transformers\n",
    "\n",
    "\"\"\"\n",
    "    article: https://www.sciencedirect.com/science/article/pii/S0167811622000477\n",
    "\"\"\"\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "siebert_roberta = pipeline(\"text-classification\", model=\"siebert/sentiment-roberta-large-english\")\n",
    "\n",
    "\n",
    "print(siebert_roberta(\"I love you!\"))\n",
    "print(siebert_roberta(\"I hate you!\"))\n",
    "print(siebert_roberta(\"neutral text\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fba1a134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing text at index 697: Positives: First time going to this place today. Let me tell you, coming from a family of chefs this was delectable, the dine in meals came out fast, they were LARGE portions, and very good temperature. We ordered the flowered onion( fried and whole), we ordered the Louisiana chook both entrees. Then I had the parmigiana as my main with mash and veg. The mash and veg was perfectly cooked, though the mash tastes a little like packet mash. The sauce with the Louisiana chicken is a little spicy so if you ca n’t tolerate a little spice the sauce is n’t for you. But man oh man the crunch on the chook and the juicy chicken was incredible, was thoroughly enjoyable. The parmigiana was LARGE so much so I could n’t finish it all. Great that they gave takeaways Negatives: The drink I ordered was the summer one in the mocktails section, tasted great only issue I really had was the lemon seeds in the drink, lucky the straws were n’t big enough to suck them up otherwise we would had an issue trying to fish multiple seeds out of the drink. We loved the Louisiana chicken so much we ordered some to take away, sadly to our disappointment the portion sizes were very different, much smaller and not as crunchy still very tasty and very juicy just not the same portion sizes as dine in( specifically regarding our dining experience) We also ordered take away chocolate churro and fruit fondu. The Churros are Exquisite as far as crunch goes but there is little to no cinnamon sugar on it. But the lack of cinnamon sugar can be covered up by the chocolate sauce and fruit eaten together bite by bite. The sauce also tasted Store bought which is still tasted good to me but may not be to everyone liking. The flowered onion, leaves much to be desired for, I definitely would n’t eat it by itself as it essentially just a whole onion fried up. The sauce was nice and it goes well with the main meal. Other: I must say they brought the mains out not long after we got our entrees which is okay. Just did n’t really get time to savour the entrees. The serves seems a little all over the place but generally very welcoming and accomodating. Also Incase anyone wants to know they have the MCCS discounts( for marines) Over all my dining experience was fantastic. Just a little disappointed with the takeaway serving sizes. And the wait for takeaway was MUCH longer than the wait for the main meal. Taste for those specific meals( besides the onion and the lack of cinnamon sugar) was great. Will definitely bring my husband and other family here again:)\n",
      "The expanded size of the tensor (574) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 574].  Tensor sizes: [1, 514]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88       611\n",
      "           1       0.85      0.93      0.89       600\n",
      "\n",
      "    accuracy                           0.88      1211\n",
      "   macro avg       0.88      0.88      0.88      1211\n",
      "weighted avg       0.88      0.88      0.88      1211\n",
      "\n",
      "0.8810900082576383\n"
     ]
    }
   ],
   "source": [
    "#siebert_roberta\n",
    "mapper = {\n",
    "    \"NEGATIVE\": 0,\n",
    "    \"POSITIVE\": 1\n",
    "} \n",
    "utils.apply_kaggle_model(siebert_roberta, mapper, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd217aff",
   "metadata": {},
   "source": [
    "### saiffff/distilbert-imdb-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd505e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.7047289609909058}]\n",
      "[{'label': 'LABEL_1', 'score': 0.9926829934120178}]\n",
      "[{'label': 'LABEL_0', 'score': 0.6355293393135071}]\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "saiffff = pipeline(\"text-classification\", model=\"saiffff/distilbert-imdb-sentiment\")\n",
    "print(saiffff(\"I don't like you!\"))\n",
    "print(saiffff(\"this is really good!\"))\n",
    "print(saiffff(\"neutral text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "863a1186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing text at index 697: Positives: First time going to this place today. Let me tell you, coming from a family of chefs this was delectable, the dine in meals came out fast, they were LARGE portions, and very good temperature. We ordered the flowered onion( fried and whole), we ordered the Louisiana chook both entrees. Then I had the parmigiana as my main with mash and veg. The mash and veg was perfectly cooked, though the mash tastes a little like packet mash. The sauce with the Louisiana chicken is a little spicy so if you ca n’t tolerate a little spice the sauce is n’t for you. But man oh man the crunch on the chook and the juicy chicken was incredible, was thoroughly enjoyable. The parmigiana was LARGE so much so I could n’t finish it all. Great that they gave takeaways Negatives: The drink I ordered was the summer one in the mocktails section, tasted great only issue I really had was the lemon seeds in the drink, lucky the straws were n’t big enough to suck them up otherwise we would had an issue trying to fish multiple seeds out of the drink. We loved the Louisiana chicken so much we ordered some to take away, sadly to our disappointment the portion sizes were very different, much smaller and not as crunchy still very tasty and very juicy just not the same portion sizes as dine in( specifically regarding our dining experience) We also ordered take away chocolate churro and fruit fondu. The Churros are Exquisite as far as crunch goes but there is little to no cinnamon sugar on it. But the lack of cinnamon sugar can be covered up by the chocolate sauce and fruit eaten together bite by bite. The sauce also tasted Store bought which is still tasted good to me but may not be to everyone liking. The flowered onion, leaves much to be desired for, I definitely would n’t eat it by itself as it essentially just a whole onion fried up. The sauce was nice and it goes well with the main meal. Other: I must say they brought the mains out not long after we got our entrees which is okay. Just did n’t really get time to savour the entrees. The serves seems a little all over the place but generally very welcoming and accomodating. Also Incase anyone wants to know they have the MCCS discounts( for marines) Over all my dining experience was fantastic. Just a little disappointed with the takeaway serving sizes. And the wait for takeaway was MUCH longer than the wait for the main meal. Taste for those specific meals( besides the onion and the lack of cinnamon sugar) was great. Will definitely bring my husband and other family here again:)\n",
      "The size of tensor a (574) must match the size of tensor b (512) at non-singleton dimension 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.79       611\n",
      "           1       0.76      0.87      0.81       600\n",
      "\n",
      "    accuracy                           0.80      1211\n",
      "   macro avg       0.81      0.80      0.80      1211\n",
      "weighted avg       0.81      0.80      0.80      1211\n",
      "\n",
      "0.8018166804293972\n"
     ]
    }
   ],
   "source": [
    "mapper = {\n",
    "    \"LABEL_0\": 0,\n",
    "    \"LABEL_1\": 1,\n",
    "}\n",
    "utils.apply_kaggle_model(saiffff, mapper, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ed0d3b",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba5c426",
   "metadata": {},
   "source": [
    "### training models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680de3f0",
   "metadata": {},
   "source": [
    "#### saiffff/distilbert-imdb-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5192a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/saiffff/distilbert-imdb-sentiment\n",
    "model_path = \"saiffff/distilbert-imdb-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95fc90bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c07f2879ea4df7b81e806730724189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/7979 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5a41a3ce9d442fadc50b6c5f37b363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/7979 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04025ac80f324562abb557c5794f4d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/7979 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e1a5c823e04b7680f1a069856d0c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/7980 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42394fdb693439bb53f228cdedeb422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/7980 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f569e7ba35bb405c912b5aeefa8d4bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1091 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0dbda22372943febf7e44bd63f00a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1090 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b9ad8262334ad8b8fefecbcf0fcfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1091 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7242f647fee344a9a1d98c68b52fe422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1091 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d173b4b0fa91404688e068e3b5afb1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1091 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3493' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3493/4990 08:18 < 03:33, 7.00 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.325200</td>\n",
       "      <td>0.285304</td>\n",
       "      <td>0.880843</td>\n",
       "      <td>0.884547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.378014</td>\n",
       "      <td>0.884510</td>\n",
       "      <td>0.887299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.535727</td>\n",
       "      <td>0.870761</td>\n",
       "      <td>0.878553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.675212</td>\n",
       "      <td>0.884510</td>\n",
       "      <td>0.893220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.758838</td>\n",
       "      <td>0.877177</td>\n",
       "      <td>0.888704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.746095</td>\n",
       "      <td>0.875344</td>\n",
       "      <td>0.886477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.849747</td>\n",
       "      <td>0.879010</td>\n",
       "      <td>0.890547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3493' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3493/4990 08:31 < 03:39, 6.82 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.262700</td>\n",
       "      <td>0.296299</td>\n",
       "      <td>0.888073</td>\n",
       "      <td>0.889493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.382961</td>\n",
       "      <td>0.888991</td>\n",
       "      <td>0.890100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.587212</td>\n",
       "      <td>0.881651</td>\n",
       "      <td>0.881760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.633065</td>\n",
       "      <td>0.889908</td>\n",
       "      <td>0.893238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.775273</td>\n",
       "      <td>0.888991</td>\n",
       "      <td>0.891285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.788367</td>\n",
       "      <td>0.888991</td>\n",
       "      <td>0.892061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.883373</td>\n",
       "      <td>0.886239</td>\n",
       "      <td>0.887067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1996' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1996/4990 05:10 < 07:45, 6.43 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.273300</td>\n",
       "      <td>0.289091</td>\n",
       "      <td>0.881760</td>\n",
       "      <td>0.867692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.097900</td>\n",
       "      <td>0.431633</td>\n",
       "      <td>0.873511</td>\n",
       "      <td>0.857732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.525089</td>\n",
       "      <td>0.870761</td>\n",
       "      <td>0.858291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>0.668384</td>\n",
       "      <td>0.880843</td>\n",
       "      <td>0.867347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2994' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2994/4990 07:14 < 04:49, 6.89 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.295500</td>\n",
       "      <td>0.258857</td>\n",
       "      <td>0.890926</td>\n",
       "      <td>0.894783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.203400</td>\n",
       "      <td>0.381676</td>\n",
       "      <td>0.874427</td>\n",
       "      <td>0.883404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.509166</td>\n",
       "      <td>0.895509</td>\n",
       "      <td>0.897666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.649577</td>\n",
       "      <td>0.887259</td>\n",
       "      <td>0.888688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.723298</td>\n",
       "      <td>0.886343</td>\n",
       "      <td>0.886654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.783081</td>\n",
       "      <td>0.892759</td>\n",
       "      <td>0.893151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1996' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1996/4990 04:50 < 07:15, 6.87 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.245980</td>\n",
       "      <td>0.896425</td>\n",
       "      <td>0.890821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.376244</td>\n",
       "      <td>0.880843</td>\n",
       "      <td>0.882459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.525369</td>\n",
       "      <td>0.890926</td>\n",
       "      <td>0.885246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.603046</td>\n",
       "      <td>0.892759</td>\n",
       "      <td>0.887175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy: 0.8896\n",
      "Average F1 Score: 0.8885\n"
     ]
    }
   ],
   "source": [
    "run_cross_validation(train_ds, val_ds, model_init, tokenizer, 'saiffff_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d43ac4d",
   "metadata": {},
   "source": [
    "### domain adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef1009",
   "metadata": {},
   "source": [
    "#### distilbert/distilbert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8cebe09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b06ece05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c132cca89b474ead7ef21325ae12d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/7979 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2994' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2994/4990 07:04 < 04:43, 7.05 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>0.299208</td>\n",
       "      <td>0.868928</td>\n",
       "      <td>0.877042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.366943</td>\n",
       "      <td>0.876260</td>\n",
       "      <td>0.884517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.493979</td>\n",
       "      <td>0.879927</td>\n",
       "      <td>0.888321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.705606</td>\n",
       "      <td>0.873511</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.781516</td>\n",
       "      <td>0.875344</td>\n",
       "      <td>0.885522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.792805</td>\n",
       "      <td>0.873511</td>\n",
       "      <td>0.883642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2495' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2495/4990 06:02 < 06:02, 6.88 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.280400</td>\n",
       "      <td>0.315443</td>\n",
       "      <td>0.876147</td>\n",
       "      <td>0.880425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.111100</td>\n",
       "      <td>0.363057</td>\n",
       "      <td>0.888991</td>\n",
       "      <td>0.893953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.499873</td>\n",
       "      <td>0.877982</td>\n",
       "      <td>0.881567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.111900</td>\n",
       "      <td>0.727809</td>\n",
       "      <td>0.883486</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.817715</td>\n",
       "      <td>0.868807</td>\n",
       "      <td>0.880734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2994' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2994/4990 07:16 < 04:51, 6.86 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.326100</td>\n",
       "      <td>0.305674</td>\n",
       "      <td>0.876260</td>\n",
       "      <td>0.859813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>0.410822</td>\n",
       "      <td>0.870761</td>\n",
       "      <td>0.858291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.129800</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.870761</td>\n",
       "      <td>0.863504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.759717</td>\n",
       "      <td>0.862511</td>\n",
       "      <td>0.851190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.792202</td>\n",
       "      <td>0.872594</td>\n",
       "      <td>0.861692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.961636</td>\n",
       "      <td>0.863428</td>\n",
       "      <td>0.852329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2994' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2994/4990 07:18 < 04:52, 6.82 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>0.286523</td>\n",
       "      <td>0.871677</td>\n",
       "      <td>0.879518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.405290</td>\n",
       "      <td>0.879010</td>\n",
       "      <td>0.885417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.425140</td>\n",
       "      <td>0.898258</td>\n",
       "      <td>0.899365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.797337</td>\n",
       "      <td>0.865261</td>\n",
       "      <td>0.863256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.745605</td>\n",
       "      <td>0.882676</td>\n",
       "      <td>0.882784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.839794</td>\n",
       "      <td>0.893676</td>\n",
       "      <td>0.895118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2994' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2994/4990 07:23 < 04:55, 6.75 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.356500</td>\n",
       "      <td>0.266315</td>\n",
       "      <td>0.887259</td>\n",
       "      <td>0.880698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.526802</td>\n",
       "      <td>0.841430</td>\n",
       "      <td>0.850216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.110600</td>\n",
       "      <td>0.392360</td>\n",
       "      <td>0.902841</td>\n",
       "      <td>0.897485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.543960</td>\n",
       "      <td>0.903758</td>\n",
       "      <td>0.896347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.670430</td>\n",
       "      <td>0.890926</td>\n",
       "      <td>0.882527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.789638</td>\n",
       "      <td>0.891842</td>\n",
       "      <td>0.881526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy: 0.8882\n",
      "Average F1 Score: 0.8885\n"
     ]
    }
   ],
   "source": [
    "run_cross_validation(train_ds, val_ds, model_init, tokenizer, 'distilbert_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d9bdf7",
   "metadata": {},
   "source": [
    "### roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df544295",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"FacebookAI/roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "def peft_model_init():\n",
    "    global model_path\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "    from peft import LoraConfig, TaskType, get_peft_model\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS, r=2, lora_alpha=16, lora_dropout=0.1, bias=\"none\",\n",
    "    )\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea1f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d5487e4a134f1cadb0359e0f0a0f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/7979 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3493' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3493/4990 11:10 < 04:47, 5.20 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>0.291398</td>\n",
       "      <td>0.887259</td>\n",
       "      <td>0.895141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>0.297508</td>\n",
       "      <td>0.886343</td>\n",
       "      <td>0.890653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.276300</td>\n",
       "      <td>0.312307</td>\n",
       "      <td>0.873511</td>\n",
       "      <td>0.876786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.286700</td>\n",
       "      <td>0.292205</td>\n",
       "      <td>0.896425</td>\n",
       "      <td>0.903993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.268100</td>\n",
       "      <td>0.294012</td>\n",
       "      <td>0.892759</td>\n",
       "      <td>0.899914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.267200</td>\n",
       "      <td>0.298114</td>\n",
       "      <td>0.887259</td>\n",
       "      <td>0.893691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.323134</td>\n",
       "      <td>0.888176</td>\n",
       "      <td>0.899007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3493' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3493/4990 11:36 < 04:58, 5.01 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.283144</td>\n",
       "      <td>0.896330</td>\n",
       "      <td>0.899556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>0.288031</td>\n",
       "      <td>0.890826</td>\n",
       "      <td>0.892502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.267000</td>\n",
       "      <td>0.296859</td>\n",
       "      <td>0.880734</td>\n",
       "      <td>0.880074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.306600</td>\n",
       "      <td>0.295606</td>\n",
       "      <td>0.896330</td>\n",
       "      <td>0.902334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.217300</td>\n",
       "      <td>0.288924</td>\n",
       "      <td>0.897248</td>\n",
       "      <td>0.901408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.290100</td>\n",
       "      <td>0.283764</td>\n",
       "      <td>0.892661</td>\n",
       "      <td>0.896368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.305786</td>\n",
       "      <td>0.892661</td>\n",
       "      <td>0.897098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4990' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4990/4990 17:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.276800</td>\n",
       "      <td>0.309514</td>\n",
       "      <td>0.884510</td>\n",
       "      <td>0.879310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.300686</td>\n",
       "      <td>0.879927</td>\n",
       "      <td>0.868342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.294410</td>\n",
       "      <td>0.879927</td>\n",
       "      <td>0.866734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>0.295033</td>\n",
       "      <td>0.887259</td>\n",
       "      <td>0.881844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.289663</td>\n",
       "      <td>0.886343</td>\n",
       "      <td>0.876740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.270300</td>\n",
       "      <td>0.294829</td>\n",
       "      <td>0.887259</td>\n",
       "      <td>0.881617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.253900</td>\n",
       "      <td>0.305467</td>\n",
       "      <td>0.889093</td>\n",
       "      <td>0.882638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.189600</td>\n",
       "      <td>0.301762</td>\n",
       "      <td>0.887259</td>\n",
       "      <td>0.882071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.218400</td>\n",
       "      <td>0.300911</td>\n",
       "      <td>0.887259</td>\n",
       "      <td>0.880234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.281800</td>\n",
       "      <td>0.304393</td>\n",
       "      <td>0.889093</td>\n",
       "      <td>0.882410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2994' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2994/4990 10:50 < 07:14, 4.60 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>0.294165</td>\n",
       "      <td>0.890009</td>\n",
       "      <td>0.893993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.253900</td>\n",
       "      <td>0.285684</td>\n",
       "      <td>0.885426</td>\n",
       "      <td>0.892334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>0.273447</td>\n",
       "      <td>0.900092</td>\n",
       "      <td>0.901536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.270018</td>\n",
       "      <td>0.899175</td>\n",
       "      <td>0.900362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>0.279205</td>\n",
       "      <td>0.892759</td>\n",
       "      <td>0.896734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.288713</td>\n",
       "      <td>0.899175</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7423/3198313530.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2994' max='4990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2994/4990 10:15 < 06:50, 4.86 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.275404</td>\n",
       "      <td>0.892759</td>\n",
       "      <td>0.891566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.293800</td>\n",
       "      <td>0.260548</td>\n",
       "      <td>0.906508</td>\n",
       "      <td>0.903409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.246411</td>\n",
       "      <td>0.912007</td>\n",
       "      <td>0.907869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.234400</td>\n",
       "      <td>0.244158</td>\n",
       "      <td>0.912007</td>\n",
       "      <td>0.907692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.245600</td>\n",
       "      <td>0.912007</td>\n",
       "      <td>0.907692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.124600</td>\n",
       "      <td>0.264031</td>\n",
       "      <td>0.908341</td>\n",
       "      <td>0.903288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy: 0.8988\n",
      "Average F1 Score: 0.8997\n"
     ]
    }
   ],
   "source": [
    "run_cross_validation(train_ds, val_ds, peft_model_init, tokenizer, 'roberta_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6048d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
